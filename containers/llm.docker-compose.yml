name: llm
services:

  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    environment:
      - TZ=${TZ}
      - "OLLAMA_BASE_URL=http://ollama:11434"
    volumes:
      - ${APP_DATA}/webservices/open-webui:/app/backend/data
    depends_on:
      - ollama
    labels:
      - traefik.enable=true
      - traefik.http.routers.openwebui.rule=Host(`llm.${ROOT_DOMAIN}`)
      - traefik.http.routers.openwebui.tls=true
      - traefik.http.routers.openwebui.entrypoints=websecure
      - traefik.http.routers.openwebui.tls.certresolver=resolver
      - traefik.http.services.openwebui.loadbalancer.server.port=8080

  ollama:
    container_name: ollama
    replace: true
    image: ollama/ollama
    restart: unless-stopped
    hostname: ollama
    environment:
      - TZ=${TZ}
      - OLLAMA_KEEP_ALIVE=24h
    volumes:
      - ${APP_DATA}/webservices/ollama:/root/.ollama
    ports:
      - "11434:11434"
    # podman syntax for nvidia support
    devices:
      - nvidia.com/gpu=all
    # nixos docker rootless syntax for nvidia support
    #    deploy:
    #      resources:
    #        reservations:
    #          devices:
    #            - driver: cdi
    #              device_ids:
    #                - nvidia.com/gpu=all
    #labels:
      #- traefik.enable=true
      #- traefik.http.routers.ollama.rule=Host(`${SECRET_OLLAMA_SUBDOMAIN}.${ROOT_DOMAIN}`)
      #- traefik.http.routers.ollama.tls=true
      #- traefik.http.routers.ollama.entrypoints=websecure
      #- traefik.http.routers.ollama.tls.certresolver=resolver
      #- traefik.http.services.ollama.loadbalancer.server.port=11434
      #- traefik.http.routers.ollama.middlewares=auth
      #- traefik.http.middlewares.auth.basicauth.users=${BASIC_AUTH_USER}:${BASIC_AUTH_PASS}

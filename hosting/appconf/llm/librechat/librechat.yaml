version: 1.3.1

# Interface Configuration
interface:
  customWelcome: "Chat Private, with Any AI"

# AI Endpoints
endpoints:
  custom:
    # Private LLM Endpoint (via LiteLLM)
    - name: "PrivateModels"
      apiKey: "${LITELLM_MASTER_KEY}"
      baseURL: "http://litellm:4000"
      modelDisplayLabel: "PrivateLLM"
      models:
        default:
          - "claude-haiku-4.5"
          - "kimi-k2-thinking"
          - "qwen3-coder"
          - "qwen3-8b"
        fetch: true
      titleModel: "claude-haiku-4.5"
      summarize: true
      summaryModel: "kimi-k2-thinking"

    # OpenRouter Endpoint
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_API_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      modelDisplayLabel: "OpenRouter"
      models:
        default:
          - "anthropic/claude-haiku-4.5"
          - "moonshotai/kimi-k2-thinking"
        fetch: true
      titleModel: "anthropic/claude-haiku-4.5"
      summarize: true
      summaryModel: "moonshotai/kimi-k2-thinking"

# MCP Servers
mcpServers:
  pricefx-dev:
    type: streamable-http
    url: http://host.docker.internal:8082/mcp/demofx-staging.pricefx.com/copilotfx
    oauth:
      client_id: librechat-dev
      authorization_url: https://demofx-staging.pricefx.com/pricefx/copilotfx/oauth/authorize
      token_url: https://demofx-staging.pricefx.com/pricefx/copilotfx/oauth/token
      redirect_uri: https://librechat.coeus.missingham.net/api/mcp/pricefx-dev/oauth/callback

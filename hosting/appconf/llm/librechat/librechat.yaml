version: 1.3.1

# Interface Configuration
interface:
  customWelcome: "Chat Private, with Any AI"

# AI Endpoints
endpoints:
  custom:
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default:
          - "z-ai/glm-4.7"
          - "moonshotai/kimi-k2-thinking"
          - "anthropic/claude-haiku-4.5"
          - "anthropic/claude-sonnet-4.5"
          - "minimax/minimax-m2.1"
          - "qwen/qwen3-coder"
          - "qwen/qwen3-235b-a22b"
          - "openai/gpt-oss-120b"
      fetch: false
      titleModel: "qwen/qwen3-coder"
      summarize: true
      summaryModel: "minimax/minimax-m2"

      # Private LLM Endpoint (via LiteLLM)
    - name: "LiteLLM"
      apiKey: "${LITELLM_MASTER_KEY}"
      baseURL: "http://litellm:4000"
      #modelDisplayLabel: "PrivateLLM"
      models:
        default:
          - "claude-haiku-4.5"
          - "kimi-k2-thinking"
          - "qwen3-coder"
          - "qwen3-8b"
        fetch: true
      titleModel: "claude-haiku-4.5"
      summarize: true
      summaryModel: "kimi-k2-thinking"

# MCP Servers
mcpServers:
  litellm:
    type: streamable-http
    url: http://litellm:4000/mcp
    headers:
      x-litellm-api-key: "Bearer ${LITELLM_MASTER_KEY}"
